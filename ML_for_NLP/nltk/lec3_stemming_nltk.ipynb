{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for explaination about stemming, refer notes!\n",
    "# in short, reduce words to their root/base stem\n",
    "words = [\"go\", \"going\", \"gone\", \"explaination\", \"explained\", \"congratulated\", \"congratulations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find root stem using Porter Stemmer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go->go\n",
      "going->go\n",
      "gone->gone\n",
      "explaination->explain\n",
      "explained->explain\n",
      "congratulated->congratul\n",
      "congratulations->congratul\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word + \"->\" + stemmer.stem(word))\n",
    "# NOTICE: congratul is not a word but it reduces the complexity. \n",
    "# however, this is a major disadvantage of stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying different stemmer: RegexpStemmer\n",
    "# this is regular expression stemming where we remove the affixes based on the exp. \n",
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_stemmer = RegexpStemmer(regexp='ing$|s$|e$|able$', min=4) # REMEMBER: provide positional argument 'regexp'\n",
    "# symbol $ represents the direction from where you want to remove the exp. \n",
    "# min represents the minimum word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eat\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "print(regex_stemmer.stem(\"eating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingeat\n"
     ]
    }
   ],
   "source": [
    "# lets change the word\n",
    "print(regex_stemmer.stem(\"ingeating\"))\n",
    "# issue will be that the prefix will be included in the output because of $ placement in the exp. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating\n"
     ]
    }
   ],
   "source": [
    "# change the stemmer exp\n",
    "regex_stemmer_new = RegexpStemmer(regexp='^ing|s$|e$|able$', min=4) # NOTICE: ^ing\n",
    "# check\n",
    "print(regex_stemmer_new.stem(\"ingeating\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another stemmer which is better than Porter: SnowballStemmer\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go->go\n",
      "going->go\n",
      "gone->gone\n",
      "explaination->explain\n",
      "explained->explain\n",
      "congratulated->congratul\n",
      "congratulations->congratul\n"
     ]
    }
   ],
   "source": [
    "snowball_stemmer = SnowballStemmer(language=\"english\")\n",
    "for word in words:\n",
    "    print(word + \"->\" + snowball_stemmer.stem(word))\n",
    "# though in these examples, we dont see any change wrt to Porter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "porter stemmer results: \n",
      "fairly -> fairli\n",
      "sportingly -> sportingli\n",
      "snowball stemmer results: \n",
      "fairly -> fair\n",
      "sportingly -> sport\n"
     ]
    }
   ],
   "source": [
    "# few examples with good results\n",
    "print(\n",
    "    \"porter stemmer results: \\n\" \n",
    "    + \"fairly -> \" \n",
    "    + stemmer.stem(\"fairly\")\n",
    "    + \"\\n\" \n",
    "    + \"sportingly -> \"\n",
    "    + stemmer.stem(\"sportingly\")\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"snowball stemmer results: \\n\" \n",
    "    + \"fairly -> \" \n",
    "    + snowball_stemmer.stem(\"fairly\")\n",
    "    + \"\\n\" \n",
    "    + \"sportingly -> \"\n",
    "    + snowball_stemmer.stem(\"sportingly\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# because of this wrong root word problem, we use Lemmatization!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-nlp_preprocess]",
   "language": "python",
   "name": "conda-env-.conda-nlp_preprocess-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
